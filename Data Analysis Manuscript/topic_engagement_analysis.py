#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Topic Engagement Analysis Script
åˆ†æä¸åŒä¸»é¢˜åœ¨ç¤¾äº¤åª’ä½“æŒ‡æ ‡ä¸Šçš„è¡¨ç°å·®å¼‚
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import shapiro, levene, kruskal, f_oneway, mannwhitneyu
from statsmodels.stats.multicomp import pairwise_tukeyhsd
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class TopicEngagementAnalyzer:
    def __init__(self):
        self.df = None
        self.results = {}
        
    def load_data(self, filename):
        """åŠ è½½LDAç»“æœæ•°æ®"""
        try:
            self.df = pd.read_excel(filename, sheet_name='Document Topic Assignment')
            print(f"âœ… æˆåŠŸåŠ è½½æ•°æ®: {len(self.df)} æ¡è®°å½•")
            
            # æ•°æ®æ¸…ç†ï¼šå¤„ç†ä¸­æ–‡æ•°å­—æ ¼å¼
            engagement_cols = ['liked_count', 'comment_count', 'share_count', 'collected_count']
            
            for col in engagement_cols:
                if col in self.df.columns:
                    # æ¸…ç†æ•°æ®ï¼šå°†ä¸­æ–‡æ•°å­—è½¬æ¢ä¸ºæ•°å­—
                    self.df[col] = self.df[col].astype(str).apply(self._convert_chinese_number)
                    # è½¬æ¢ä¸ºæ•°å€¼ç±»å‹ï¼Œæ— æ³•è½¬æ¢çš„è®¾ä¸ºNaN
                    self.df[col] = pd.to_numeric(self.df[col], errors='coerce')
                    print(f"ğŸ“Š {col}: æ¸…ç†åæœ‰æ•ˆæ•°æ® {self.df[col].notna().sum()}/{len(self.df)} æ¡")
            
            # ä¿®æ­£topicæ ‡å·ï¼šå°†0-4æ˜ å°„åˆ°1-5
            self.df['dominant_topic'] = self.df['dominant_topic'] + 1
            
            print(f"ğŸ“Š ä¸»é¢˜åˆ†å¸ƒ (ä¿®æ­£åæ ‡å·):")
            print(self.df['dominant_topic'].value_counts().sort_index())
            return True
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False
    
    def _convert_chinese_number(self, value):
        """è½¬æ¢ä¸­æ–‡æ•°å­—æ ¼å¼ä¸ºæ•°å­—"""
        if pd.isna(value) or value == '':
            return np.nan
        
        value = str(value).strip()
        
        # å¤„ç†"ä¸‡"å•ä½
        if 'ä¸‡' in value:
            # æå–æ•°å­—éƒ¨åˆ†
            import re
            numbers = re.findall(r'[\d.]+', value)
            if numbers:
                try:
                    num = float(numbers[0])
                    return num * 10000  # ä¸‡è½¬æ¢ä¸ºå…·ä½“æ•°å­—
                except:
                    return np.nan
        
        # å¤„ç†"åƒ"å•ä½
        elif 'åƒ' in value:
            import re
            numbers = re.findall(r'[\d.]+', value)
            if numbers:
                try:
                    num = float(numbers[0])
                    return num * 1000  # åƒè½¬æ¢ä¸ºå…·ä½“æ•°å­—
                except:
                    return np.nan
        
        # å¤„ç†çº¯æ•°å­—
        elif value.replace('.', '').replace('-', '').isdigit():
            try:
                return float(value)
            except:
                return np.nan
        
        # å¤„ç†åŒ…å«"+"çš„æƒ…å†µ
        elif '+' in value:
            # æå–ç¬¬ä¸€ä¸ªæ•°å­—
            import re
            numbers = re.findall(r'[\d.]+', value)
            if numbers:
                try:
                    return float(numbers[0])
                except:
                    return np.nan
        
        # å…¶ä»–æƒ…å†µè¿”å›NaN
        return np.nan
    
    def descriptive_statistics(self):
        """æè¿°æ€§ç»Ÿè®¡åˆ†æ"""
        print("\nğŸ“Š === æè¿°æ€§ç»Ÿè®¡åˆ†æ ===")
        
        # æŒ‰ä¸»é¢˜åˆ†ç»„çš„æè¿°æ€§ç»Ÿè®¡
        engagement_cols = ['liked_count', 'comment_count', 'share_count', 'collected_count']
        
        for col in engagement_cols:
            print(f"\nğŸ” {col} ç»Ÿè®¡:")
            grouped = self.df.groupby('dominant_topic')[col]
            stats = grouped.agg(['count', 'mean', 'std', 'median', 'min', 'max'])
            print(stats.round(2))
            
            # ä¿å­˜åˆ°ç»“æœå­—å…¸
            self.results[f'{col}_descriptive'] = stats
    
    def normality_test(self):
        """æ­£æ€æ€§æ£€éªŒ"""
        print("\nğŸ“ˆ === æ­£æ€æ€§æ£€éªŒ (Shapiro-Wilk) ===")
        
        engagement_cols = ['liked_count', 'comment_count', 'share_count', 'collected_count']
        normality_results = {}
        
        for col in engagement_cols:
            print(f"\nğŸ” {col}:")
            col_results = {}
            
            for topic in sorted(self.df['dominant_topic'].unique()):
                data = self.df[self.df['dominant_topic'] == topic][col].dropna()
                if len(data) > 3:  # è‡³å°‘éœ€è¦3ä¸ªæ•°æ®ç‚¹
                    stat, p_value = shapiro(data)
                    print(f"  Topic {topic}: p={p_value:.4f} {'âœ…' if p_value > 0.05 else 'âŒ'}")
                    col_results[topic] = {'statistic': stat, 'p_value': p_value, 'is_normal': p_value > 0.05}
                else:
                    print(f"  Topic {topic}: æ•°æ®ä¸è¶³")
                    col_results[topic] = {'statistic': np.nan, 'p_value': np.nan, 'is_normal': False}
            
            normality_results[col] = col_results
        
        self.results['normality_test'] = normality_results
        return normality_results
    
    def variance_homogeneity_test(self):
        """æ–¹å·®é½æ€§æ£€éªŒ"""
        print("\nğŸ“Š === æ–¹å·®é½æ€§æ£€éªŒ (Levene) ===")
        
        engagement_cols = ['liked_count', 'comment_count', 'share_count', 'collected_count']
        variance_results = {}
        
        for col in engagement_cols:
            print(f"\nğŸ” {col}:")
            
            # å‡†å¤‡å„ç»„æ•°æ®
            groups = []
            group_labels = []
            
            for topic in sorted(self.df['dominant_topic'].unique()):
                data = self.df[self.df['dominant_topic'] == topic][col].dropna()
                if len(data) > 1:
                    groups.append(data)
                    group_labels.append(f'Topic_{topic}')
            
            if len(groups) > 1:
                stat, p_value = levene(*groups)
                print(f"  Leveneæ£€éªŒ: p={p_value:.4f} {'âœ…' if p_value > 0.05 else 'âŒ'}")
                variance_results[col] = {'statistic': stat, 'p_value': p_value, 'is_homogeneous': p_value > 0.05}
            else:
                print("  æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œæ–¹å·®é½æ€§æ£€éªŒ")
                variance_results[col] = {'statistic': np.nan, 'p_value': np.nan, 'is_homogeneous': False}
        
        self.results['variance_test'] = variance_results
        return variance_results
    
    def mean_difference_test(self):
        """å‡å€¼å·®å¼‚æ£€éªŒ"""
        print("\nğŸ¯ === å‡å€¼å·®å¼‚æ£€éªŒ ===")
        
        engagement_cols = ['liked_count', 'comment_count', 'share_count', 'collected_count']
        difference_results = {}
        
        for col in engagement_cols:
            print(f"\nğŸ” {col}:")
            
            # å‡†å¤‡å„ç»„æ•°æ®
            groups = []
            group_labels = []
            
            for topic in sorted(self.df['dominant_topic'].unique()):
                data = self.df[self.df['dominant_topic'] == topic][col].dropna()
                if len(data) > 1:
                    groups.append(data)
                    group_labels.append(f'Topic_{topic}')
            
            if len(groups) > 1:
                # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ç»„éƒ½æ­£æ€åˆ†å¸ƒ
                normality_results = self.results.get('normality_test', {}).get(col, {})
                all_normal = all(result.get('is_normal', False) for result in normality_results.values())
                
                # æ£€æŸ¥æ–¹å·®é½æ€§
                variance_results = self.results.get('variance_test', {}).get(col, {})
                is_homogeneous = variance_results.get('is_homogeneous', False)
                
                if all_normal and is_homogeneous:
                    # ä½¿ç”¨ANOVA
                    stat, p_value = f_oneway(*groups)
                    test_type = 'ANOVA'
                    print(f"  ANOVA: p={p_value:.4f} {'âœ…' if p_value < 0.05 else 'âŒ'}")
                else:
                    # ä½¿ç”¨Kruskal-Wallis
                    stat, p_value = kruskal(*groups)
                    test_type = 'Kruskal-Wallis'
                    print(f"  Kruskal-Wallis: p={p_value:.4f} {'âœ…' if p_value < 0.05 else 'âŒ'}")
                
                # äº‹åå¤šé‡æ¯”è¾ƒ
                post_hoc_results = None
                if p_value < 0.05:
                    print("  ğŸ“‹ äº‹åå¤šé‡æ¯”è¾ƒ:")
                    if test_type == 'ANOVA':
                        # Tukey HSD
                        tukey = pairwise_tukeyhsd(self.df[col], self.df['dominant_topic'])
                        print(tukey)
                        post_hoc_results = tukey
                    else:
                        # å¯¹äºéå‚æ•°æ£€éªŒï¼Œè¿›è¡Œä¸¤ä¸¤æ¯”è¾ƒ
                        print("  ä¸¤ä¸¤æ¯”è¾ƒ (Mann-Whitney U):")
                        for i in range(len(groups)):
                            for j in range(i+1, len(groups)):
                                stat, p_val = mannwhitneyu(groups[i], groups[j], alternative='two-sided')
                                print(f"    {group_labels[i]} vs {group_labels[j]}: p={p_val:.4f}")
                
                difference_results[col] = {
                    'test_type': test_type,
                    'statistic': stat,
                    'p_value': p_value,
                    'is_significant': p_value < 0.05,
                    'post_hoc': post_hoc_results
                }
            else:
                print("  æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œå·®å¼‚æ£€éªŒ")
                difference_results[col] = {
                    'test_type': 'N/A',
                    'statistic': np.nan,
                    'p_value': np.nan,
                    'is_significant': False,
                    'post_hoc': None
                }
        
        self.results['difference_test'] = difference_results
        return difference_results
    
    def create_visualizations(self):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        print("\nğŸ“Š === åˆ›å»ºå¯è§†åŒ–å›¾è¡¨ ===")
        
        engagement_cols = ['liked_count', 'comment_count', 'share_count', 'collected_count']
        
        # åˆ›å»ºå­å›¾
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        axes = axes.ravel()
        
        for i, col in enumerate(engagement_cols):
            ax = axes[i]
            
            # ç®±çº¿å›¾
            sns.boxplot(x='dominant_topic', y=col, data=self.df, ax=ax)
            ax.set_title(f'{col} by Topic', fontsize=14, fontweight='bold')
            ax.set_xlabel('Topic', fontsize=12)
            ax.set_ylabel(col, fontsize=12)
            
            # æ·»åŠ å‡å€¼ç‚¹
            means = self.df.groupby('dominant_topic')[col].mean()
            for j, topic in enumerate(sorted(self.df['dominant_topic'].unique())):
                if topic in means.index:
                    ax.scatter(j, means[topic], color='red', s=100, zorder=5, label='Mean' if j == 0 else "")
        
        plt.tight_layout()
        plt.savefig('topic_engagement_analysis.png', dpi=300, bbox_inches='tight')
        print("âœ… å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜: topic_engagement_analysis.png")
        plt.close()
        
        # åˆ›å»ºå°æç´å›¾
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        axes = axes.ravel()
        
        for i, col in enumerate(engagement_cols):
            ax = axes[i]
            
            # å°æç´å›¾
            sns.violinplot(x='dominant_topic', y=col, data=self.df, ax=ax)
            ax.set_title(f'{col} Distribution by Topic', fontsize=14, fontweight='bold')
            ax.set_xlabel('Topic', fontsize=12)
            ax.set_ylabel(col, fontsize=12)
        
        plt.tight_layout()
        plt.savefig('topic_engagement_distribution.png', dpi=300, bbox_inches='tight')
        print("âœ… åˆ†å¸ƒå›¾å·²ä¿å­˜: topic_engagement_distribution.png")
        plt.close()
    
    def save_results(self, filename='topic_engagement_analysis_results.xlsx'):
        """ä¿å­˜åˆ†æç»“æœåˆ°Excelæ–‡ä»¶"""
        print(f"\nğŸ’¾ === ä¿å­˜åˆ†æç»“æœ ===")
        
        with pd.ExcelWriter(filename, engine='openpyxl') as writer:
            # 1. æè¿°æ€§ç»Ÿè®¡
            for col in ['liked_count', 'comment_count', 'share_count', 'collected_count']:
                if f'{col}_descriptive' in self.results:
                    self.results[f'{col}_descriptive'].to_excel(writer, sheet_name=f'{col}_descriptive')
            
            # 2. æ­£æ€æ€§æ£€éªŒç»“æœ
            normality_df = pd.DataFrame()
            for col in ['liked_count', 'comment_count', 'share_count', 'collected_count']:
                if 'normality_test' in self.results and col in self.results['normality_test']:
                    col_results = self.results['normality_test'][col]
                    for topic, result in col_results.items():
                        normality_df.loc[f'{col}_Topic_{topic}', 'statistic'] = result['statistic']
                        normality_df.loc[f'{col}_Topic_{topic}', 'p_value'] = result['p_value']
                        normality_df.loc[f'{col}_Topic_{topic}', 'is_normal'] = result['is_normal']
            
            if not normality_df.empty:
                normality_df.to_excel(writer, sheet_name='normality_test')
            
            # 3. æ–¹å·®é½æ€§æ£€éªŒç»“æœ
            variance_df = pd.DataFrame()
            for col in ['liked_count', 'comment_count', 'share_count', 'collected_count']:
                if 'variance_test' in self.results and col in self.results['variance_test']:
                    result = self.results['variance_test'][col]
                    variance_df.loc[col, 'statistic'] = result['statistic']
                    variance_df.loc[col, 'p_value'] = result['p_value']
                    variance_df.loc[col, 'is_homogeneous'] = result['is_homogeneous']
            
            if not variance_df.empty:
                variance_df.to_excel(writer, sheet_name='variance_test')
            
            # 4. å‡å€¼å·®å¼‚æ£€éªŒç»“æœ
            difference_df = pd.DataFrame()
            for col in ['liked_count', 'comment_count', 'share_count', 'collected_count']:
                if 'difference_test' in self.results and col in self.results['difference_test']:
                    result = self.results['difference_test'][col]
                    difference_df.loc[col, 'test_type'] = result['test_type']
                    difference_df.loc[col, 'statistic'] = result['statistic']
                    difference_df.loc[col, 'p_value'] = result['p_value']
                    difference_df.loc[col, 'is_significant'] = result['is_significant']
            
            if not difference_df.empty:
                difference_df.to_excel(writer, sheet_name='difference_test')
            
            # 5. åŸå§‹æ•°æ®
            self.df.to_excel(writer, sheet_name='raw_data', index=False)
        
        print(f"âœ… åˆ†æç»“æœå·²ä¿å­˜: {filename}")
    
    def run_analysis(self, input_filename):
        """è¿è¡Œå®Œæ•´åˆ†ææµç¨‹"""
        print("ğŸ” === ä¸»é¢˜å‚ä¸åº¦åˆ†æ ===")
        print("=" * 50)
        
        # 1. åŠ è½½æ•°æ®
        if not self.load_data(input_filename):
            return False
        
        # 2. æè¿°æ€§ç»Ÿè®¡
        self.descriptive_statistics()
        
        # 3. æ­£æ€æ€§æ£€éªŒ
        self.normality_test()
        
        # 4. æ–¹å·®é½æ€§æ£€éªŒ
        self.variance_homogeneity_test()
        
        # 5. å‡å€¼å·®å¼‚æ£€éªŒ
        self.mean_difference_test()
        
        # 6. åˆ›å»ºå¯è§†åŒ–
        self.create_visualizations()
        
        # 7. ä¿å­˜ç»“æœ
        self.save_results()
        
        print("\nğŸ‰ === åˆ†æå®Œæˆ ===")
        return True

def main():
    """ä¸»å‡½æ•°"""
    analyzer = TopicEngagementAnalyzer()
    
    # ä½¿ç”¨æŒ‡å®šçš„LDAç»“æœæ–‡ä»¶
    target_file = 'optimized_lda_results_a0.1_b0.5_t5.xlsx'
    
    if os.path.exists(target_file):
        print(f"ğŸ“ ä½¿ç”¨æŒ‡å®šçš„LDAç»“æœæ–‡ä»¶: {target_file}")
        analyzer.run_analysis(target_file)
    else:
        print(f"âŒ æŒ‡å®šçš„æ–‡ä»¶ä¸å­˜åœ¨: {target_file}")
        print("ğŸ’¡ è¯·ç¡®ä¿æ–‡ä»¶å­˜åœ¨äºå½“å‰ç›®å½•ä¸­")
        
        # å¦‚æœæŒ‡å®šæ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ˜¾ç¤ºå¯ç”¨çš„æ–‡ä»¶
        import glob
        lda_files = glob.glob('optimized_lda_results_*.xlsx')
        if lda_files:
            print(f"ğŸ“‹ å½“å‰ç›®å½•å¯ç”¨çš„LDAç»“æœæ–‡ä»¶:")
            for file in lda_files:
                print(f"  - {file}")
        else:
            print("âŒ å½“å‰ç›®å½•æ²¡æœ‰æ‰¾åˆ°ä»»ä½•LDAç»“æœæ–‡ä»¶")

if __name__ == "__main__":
    import os
    main() 